{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Models, Data, and Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST('./data', download = True,\n",
    "                                            train = True, transform = transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data', download = True,\n",
    "                                            train = False, transform = transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 4,\n",
    "                                         shuffle = True, num_workers = 2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size = 4,\n",
    "                                         shuffle = False, num_workers = 2)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel = False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim = 0)\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap = 'Greys')\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "out = net(images)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "matplotlib_imshow(img_grid, one_channel = True)\n",
    "\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a “Projector” to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_random(data, labels, n = 100):\n",
    "    assert len(data) == len(labels)\n",
    "    \n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "features = images.view(-1, 28 * 28)\n",
    "\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 4, 5, 1, 6, 8, 2, 0, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking model training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    output = net(images)\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes_preds(net, images, labels):\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.\n",
    "for epoch in range(1):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)            \n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step = epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing trained models with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = []\n",
    "class_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "        \n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "        \n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = dataiter.next()\n",
    "# outputs = net(images)\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = [F.softmax(el, dim=0) for el in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step = 0):\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step = global_step)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
